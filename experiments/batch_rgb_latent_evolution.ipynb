{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch RGB Latent Evolution: Multiple Colored Shapes with Spatial Diversity\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/jtooates/blind_lm/blob/main/experiments/batch_rgb_latent_evolution.ipynb)\n",
    "\n",
    "This notebook evolves a **batch of RGB latent images** simultaneously using InfoNCE patch coherence + spatial diversity loss.\n",
    "\n",
    "**Purpose**: Understand how spatial diversity loss encourages different spatial patterns across the batch.\n",
    "\n",
    "**Workflow**:\n",
    "1. Configure loss weights (including spatial diversity)\n",
    "2. Start with batch of random RGB noise  \n",
    "3. Watch them transform into diverse colored shapes frame-by-frame\n",
    "\n",
    "**Key differences from single-latent version**:\n",
    "- Batch dimension `[B, 3, H, W]` instead of `[3, H, W]`\n",
    "- Spatial diversity loss penalizes similar spatial patterns\n",
    "- Visualizations show all latents in the batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_losses(latents, patch_size=3, num_samples=100, temperature=1.0,\n",
    "                   positive_radius=3.0, negative_radius=11.0,\n",
    "                   spatial_diversity_temperature=0.5):\n",
    "    \"\"\"\n",
    "    Compute loss components for batch of RGB latents [B, 3, H, W].\n",
    "    Returns dict of individual losses.\n",
    "    \n",
    "    Args:\n",
    "        latents: [B, 3, H, W] tensor (batch of RGB images)\n",
    "        patch_size: Size of patches for InfoNCE (default 3x3x3)\n",
    "        num_samples: Number of anchor patches to sample for InfoNCE per image\n",
    "        temperature: Temperature for InfoNCE similarity\n",
    "        positive_radius: Max distance (pixels) for positive pairs in InfoNCE\n",
    "        negative_radius: Min distance (pixels) for negative pairs in InfoNCE\n",
    "        spatial_diversity_temperature: Temperature for spatial diversity loss\n",
    "    \"\"\"\n",
    "    B, C, H, W = latents.shape\n",
    "    losses = {}\n",
    "    \n",
    "    # 1. Magnitude: prevents collapse to near-zero values\n",
    "    magnitude = torch.mean(torch.abs(latents))\n",
    "    min_magnitude = 0.3\n",
    "    losses['magnitude'] = torch.relu(min_magnitude - magnitude)\n",
    "    \n",
    "    # 2. InfoNCE RGB patch coherence (per image in batch)\n",
    "    pad = patch_size // 2\n",
    "    latents_padded = F.pad(latents, (pad, pad, pad, pad), mode='replicate')\n",
    "    \n",
    "    # Extract patches: [B, 3*patch_size^2, H*W]\n",
    "    patches = F.unfold(latents_padded, kernel_size=patch_size, stride=1)\n",
    "    patches = patches.permute(0, 2, 1)  # [B, H*W, 3*patch_size^2]\n",
    "    \n",
    "    infonce_loss = 0.0\n",
    "    num_positions = H * W\n",
    "    \n",
    "    # Process each image in batch\n",
    "    for b in range(B):\n",
    "        batch_patches = patches[b]  # [H*W, 3*patch_size^2]\n",
    "        \n",
    "        # Sample anchor positions\n",
    "        n_samples = min(num_samples, num_positions)\n",
    "        anchor_indices = torch.randperm(num_positions, device=latents.device)[:n_samples]\n",
    "        anchor_patches = batch_patches[anchor_indices]  # [n_samples, 3*patch_size^2]\n",
    "        \n",
    "        # Coordinates\n",
    "        anchor_coords = torch.stack([\n",
    "            anchor_indices // W,\n",
    "            anchor_indices % W\n",
    "        ], dim=1).float()\n",
    "        \n",
    "        y_coords = torch.arange(H, device=latents.device).unsqueeze(1).expand(H, W).reshape(-1)\n",
    "        x_coords = torch.arange(W, device=latents.device).unsqueeze(0).expand(H, W).reshape(-1)\n",
    "        all_coords = torch.stack([y_coords, x_coords], dim=1).float()\n",
    "        \n",
    "        for i in range(n_samples):\n",
    "            anchor_patch = anchor_patches[i:i+1]\n",
    "            anchor_coord = anchor_coords[i:i+1]\n",
    "            \n",
    "            distances = torch.norm(all_coords - anchor_coord, dim=1)\n",
    "            pos_mask = (distances > 0) & (distances <= positive_radius)\n",
    "            neg_mask = distances > negative_radius\n",
    "            \n",
    "            if pos_mask.sum() > 0 and neg_mask.sum() > 0:\n",
    "                anchor_norm = F.normalize(anchor_patch, dim=1)\n",
    "                patches_norm = F.normalize(batch_patches, dim=1)\n",
    "                similarities = torch.matmul(anchor_norm, patches_norm.t()).squeeze(0)\n",
    "                \n",
    "                pos_sims = similarities[pos_mask] / temperature\n",
    "                neg_sims = similarities[neg_mask] / temperature\n",
    "                \n",
    "                pos_exp = torch.exp(pos_sims)\n",
    "                neg_exp = torch.exp(neg_sims)\n",
    "                \n",
    "                infonce_loss += -torch.log(pos_exp.mean() / (pos_exp.mean() + neg_exp.mean() + 1e-8))\n",
    "    \n",
    "    losses['coherence_infonce'] = infonce_loss / (B * max(num_samples, 1))\n",
    "    \n",
    "    # 3. Spatial Diversity Loss (encourages different spatial patterns)\n",
    "    if B > 1:\n",
    "        # Compute spatial intensity (color-agnostic): [B, H, W]\n",
    "        # L2 norm across RGB channels\n",
    "        spatial_intensity = latents.norm(dim=1)  # [B, H, W]\n",
    "        \n",
    "        # Flatten and normalize: [B, H*W]\n",
    "        spatial_flat = spatial_intensity.reshape(B, -1)\n",
    "        spatial_norm = F.normalize(spatial_flat, dim=1)\n",
    "        \n",
    "        # Compute pairwise similarity: [B, B]\n",
    "        similarity = torch.mm(spatial_norm, spatial_norm.t())\n",
    "        similarity = similarity / spatial_diversity_temperature\n",
    "        \n",
    "        # Mask diagonal\n",
    "        mask = torch.eye(B, device=latents.device, dtype=torch.bool)\n",
    "        similarity = similarity.masked_fill(mask, 0)\n",
    "        \n",
    "        # Average similarity (we want to minimize this)\n",
    "        losses['spatial_diversity'] = similarity.sum() / (B * (B - 1))\n",
    "    else:\n",
    "        losses['spatial_diversity'] = torch.tensor(0.0, device=latents.device)\n",
    "    \n",
    "    return losses\n",
    "\n",
    "print(\"✓ Loss functions defined\")\n",
    "print(\"\\nLoss components:\")\n",
    "print(\"  magnitude:            Prevents collapse to zero\")\n",
    "print(\"  coherence_infonce:    RGB patch similarity (nearby=positive, distant=negative)\")\n",
    "print(\"  spatial_diversity:    Encourages different spatial patterns across batch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configure Loss Weights and Parameters\n",
    "\n",
    "**Adjust these to control what the images look like!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# LOSS WEIGHTS - EXPERIMENT WITH THESE!\n",
    "# ============================================================================\n",
    "\n",
    "weights = {\n",
    "    # Magnitude: prevents collapse to near-zero values\n",
    "    'magnitude': 5.0,\n",
    "    \n",
    "    # InfoNCE: encourages nearby patches to be similar, distant patches to differ\n",
    "    'coherence_infonce': 2.0,\n",
    "    \n",
    "    # Spatial diversity: encourages different spatial patterns across batch\n",
    "    'spatial_diversity': 2.0,\n",
    "}\n",
    "\n",
    "# ============================================================================\n",
    "# INFONCE PARAMETERS\n",
    "# ============================================================================\n",
    "\n",
    "infonce_patch_size = 3          # Patch size for InfoNCE (3x3x3 for RGB)\n",
    "infonce_num_samples = 25        # Number of anchor patches per image\n",
    "infonce_temperature = 1.0       # Temperature for similarity\n",
    "infonce_positive_radius = 3.0   # Max distance for positive pairs\n",
    "infonce_negative_radius = 11.0  # Min distance for negative pairs\n",
    "\n",
    "# ============================================================================\n",
    "# SPATIAL DIVERSITY PARAMETERS\n",
    "# ============================================================================\n",
    "\n",
    "spatial_diversity_temperature = 0.1  # Lower = stronger penalty for similar patterns\n",
    "\n",
    "# ============================================================================\n",
    "# OPTIMIZATION SETTINGS\n",
    "# ============================================================================\n",
    "\n",
    "batch_size = 4               # Number of latents to evolve simultaneously\n",
    "num_steps = 250              # Total optimization steps\n",
    "snapshot_interval = 25       # Save visualization every N steps\n",
    "learning_rate = 0.02         # Adam learning rate\n",
    "image_size = 32              # Latent is 32x32 per channel\n",
    "random_seed = 42             # For reproducibility (None = random)\n",
    "\n",
    "# ============================================================================\n",
    "\n",
    "print(\"Configuration:\")\n",
    "print(f\"  Batch size: {batch_size}\")\n",
    "print(f\"  RGB latent size per image: [3, {image_size}, {image_size}]\")\n",
    "print(f\"  Total batch shape: [{batch_size}, 3, {image_size}, {image_size}]\")\n",
    "print(f\"  Total steps: {num_steps}\")\n",
    "print(f\"  Snapshots every {snapshot_interval} steps\")\n",
    "print(f\"  Learning rate: {learning_rate}\")\n",
    "\n",
    "print(f\"\\nInfoNCE parameters:\")\n",
    "print(f\"  Patch size: {infonce_patch_size}x{infonce_patch_size}x3 (RGB)\")\n",
    "print(f\"  Samples per image: {infonce_num_samples}\")\n",
    "print(f\"  Temperature: {infonce_temperature}\")\n",
    "print(f\"  Positive radius: {infonce_positive_radius} pixels\")\n",
    "print(f\"  Negative radius: {infonce_negative_radius} pixels\")\n",
    "\n",
    "print(f\"\\nSpatial diversity parameters:\")\n",
    "print(f\"  Temperature: {spatial_diversity_temperature}\")\n",
    "print(f\"  (Lower = stronger penalty for similar spatial patterns)\")\n",
    "\n",
    "print(f\"\\nActive losses:\")\n",
    "for name, weight in weights.items():\n",
    "    if weight > 0:\n",
    "        print(f\"  {name:30s}: {weight:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initialize Batch of RGB Latents\n",
    "\n",
    "Start with Gaussian noise for each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed if specified\n",
    "if random_seed is not None:\n",
    "    torch.manual_seed(random_seed)\n",
    "    np.random.seed(random_seed)\n",
    "\n",
    "# Initialize batch of RGB latents [B, 3, H, W]\n",
    "latents = torch.randn(batch_size, 3, image_size, image_size) * 0.1\n",
    "latents = latents.to(device)\n",
    "latents.requires_grad_(True)\n",
    "\n",
    "# Helper function to convert latent to displayable RGB\n",
    "def latent_to_rgb(latent_chw):\n",
    "    \"\"\"Convert [3, H, W] tensor to [H, W, 3] numpy for display, normalized to [0, 1]\"\"\"\n",
    "    rgb = latent_chw.detach().cpu().numpy()\n",
    "    rgb = np.transpose(rgb, (1, 2, 0))  # [3, H, W] -> [H, W, 3]\n",
    "    # Normalize from [-1.5, 1.5] to [0, 1]\n",
    "    rgb = (rgb + 1.5) / 3.0\n",
    "    rgb = np.clip(rgb, 0, 1)\n",
    "    return rgb\n",
    "\n",
    "# Visualize initial state\n",
    "fig, axes = plt.subplots(1, batch_size, figsize=(3 * batch_size, 3))\n",
    "if batch_size == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for i in range(batch_size):\n",
    "    rgb = latent_to_rgb(latents[i])\n",
    "    axes[i].imshow(rgb)\n",
    "    axes[i].set_title(f'Latent {i+1}', fontsize=10)\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.suptitle('Initial RGB Latents (Step 0)', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"✓ Initialized latents: {latents.shape}\")\n",
    "print(f\"  Min value: {latents.min().item():.3f}\")\n",
    "print(f\"  Max value: {latents.max().item():.3f}\")\n",
    "print(f\"  Mean value: {latents.mean().item():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run Optimization with Snapshots\n",
    "\n",
    "Watch the latents evolve step by step!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset optimizer\n",
    "optimizer = torch.optim.Adam([latents], lr=learning_rate)\n",
    "\n",
    "# Storage for snapshots\n",
    "snapshots = []  # List of [B, 3, H, W] numpy arrays\n",
    "snapshot_steps = []\n",
    "loss_history = []\n",
    "loss_components_history = {name: [] for name in weights.keys()}\n",
    "\n",
    "# Save initial state\n",
    "snapshots.append(latents.detach().cpu().numpy().copy())\n",
    "snapshot_steps.append(0)\n",
    "\n",
    "print(\"Starting optimization...\\n\")\n",
    "\n",
    "for step in range(num_steps):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Compute all losses\n",
    "    losses = compute_losses(\n",
    "        latents,\n",
    "        patch_size=infonce_patch_size,\n",
    "        num_samples=infonce_num_samples,\n",
    "        temperature=infonce_temperature,\n",
    "        positive_radius=infonce_positive_radius,\n",
    "        negative_radius=infonce_negative_radius,\n",
    "        spatial_diversity_temperature=spatial_diversity_temperature\n",
    "    )\n",
    "    \n",
    "    # Build weighted total loss\n",
    "    total_loss = sum(losses[name] * weights[name] for name in losses if name in weights)\n",
    "    \n",
    "    # Optimize\n",
    "    total_loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Clamp to valid range\n",
    "    with torch.no_grad():\n",
    "        latents.clamp_(-1.5, 1.5)\n",
    "    \n",
    "    loss_history.append(total_loss.item())\n",
    "    \n",
    "    # Save snapshot\n",
    "    if (step + 1) % snapshot_interval == 0:\n",
    "        snapshots.append(latents.detach().cpu().numpy().copy())\n",
    "        snapshot_steps.append(step + 1)\n",
    "        \n",
    "        # Print loss breakdown\n",
    "        loss_str = f\"Step {step + 1:3d}/{num_steps}: Loss = {total_loss.item():.4f}\"\n",
    "        component_strs = []\n",
    "        for name in weights:\n",
    "            if weights[name] > 0:\n",
    "                component_strs.append(f\"{name}={losses[name].item():.3f}\")\n",
    "        loss_str += \" (\" + \", \".join(component_strs) + \")\"\n",
    "        print(loss_str)\n",
    "\n",
    "# Save final state if not already saved\n",
    "if num_steps % snapshot_interval != 0:\n",
    "    snapshots.append(latents.detach().cpu().numpy().copy())\n",
    "    snapshot_steps.append(num_steps)\n",
    "\n",
    "print(f\"\\n✓ Optimization complete!\")\n",
    "print(f\"  Captured {len(snapshots)} snapshots\")\n",
    "print(f\"  Final loss: {loss_history[-1]:.4f}\")\n",
    "print(f\"  Initial loss: {loss_history[0]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualize Evolution\n",
    "\n",
    "See all snapshots for all latents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show evolution of each latent over time\n",
    "num_snapshots = len(snapshots)\n",
    "\n",
    "fig, axes = plt.subplots(batch_size, num_snapshots, figsize=(3 * num_snapshots, 3 * batch_size))\n",
    "if batch_size == 1:\n",
    "    axes = axes.reshape(1, -1)\n",
    "if num_snapshots == 1:\n",
    "    axes = axes.reshape(-1, 1)\n",
    "\n",
    "for b in range(batch_size):\n",
    "    for s, (snapshot, step) in enumerate(zip(snapshots, snapshot_steps)):\n",
    "        ax = axes[b, s]\n",
    "        rgb = latent_to_rgb(torch.tensor(snapshot[b]))\n",
    "        ax.imshow(rgb)\n",
    "        if b == 0:\n",
    "            ax.set_title(f'Step {step}', fontsize=10)\n",
    "        if s == 0:\n",
    "            ax.set_ylabel(f'Latent {b+1}', fontsize=10, rotation=0, labelpad=30)\n",
    "        ax.axis('off')\n",
    "\n",
    "plt.suptitle('RGB Latent Evolution Over Time', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nEvolution summary:\")\n",
    "print(f\"  {batch_size} latents evolved from step {snapshot_steps[0]} → {snapshot_steps[-1]}\")\n",
    "print(f\"  Look for diverse spatial patterns across the rows!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Side-by-Side Comparison\n",
    "\n",
    "Initial vs Final for all latents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, batch_size, figsize=(3 * batch_size, 6))\n",
    "if batch_size == 1:\n",
    "    axes = axes.reshape(-1, 1)\n",
    "\n",
    "# Initial (top row)\n",
    "for i in range(batch_size):\n",
    "    rgb = latent_to_rgb(torch.tensor(snapshots[0][i]))\n",
    "    axes[0, i].imshow(rgb)\n",
    "    axes[0, i].set_title(f'Latent {i+1} - Initial', fontsize=10)\n",
    "    axes[0, i].axis('off')\n",
    "\n",
    "# Final (bottom row)\n",
    "for i in range(batch_size):\n",
    "    rgb = latent_to_rgb(torch.tensor(snapshots[-1][i]))\n",
    "    axes[1, i].imshow(rgb)\n",
    "    axes[1, i].set_title(f'Latent {i+1} - Final', fontsize=10)\n",
    "    axes[1, i].axis('off')\n",
    "\n",
    "plt.suptitle('Transformation: Noise → Diverse Colored Shapes', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nNotice how each latent developed a different spatial pattern!\")\n",
    "print(\"This is the effect of the spatial diversity loss.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Plot Loss Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(loss_history, linewidth=2)\n",
    "\n",
    "# Mark snapshot points\n",
    "for step in snapshot_steps[1:]:\n",
    "    if step < len(loss_history):\n",
    "        plt.axvline(x=step, color='red', alpha=0.3, linestyle='--', linewidth=1)\n",
    "\n",
    "plt.xlabel('Optimization Step', fontsize=12)\n",
    "plt.ylabel('Total Loss', fontsize=12)\n",
    "plt.title('Loss During Optimization (red lines = snapshots)', fontsize=14)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Loss reduction: {(loss_history[0] - loss_history[-1]) / abs(loss_history[0]) * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Compute Spatial Diversity Metric\n",
    "\n",
    "Measure how different the spatial patterns are over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_pairwise_similarity(latents_bchw):\n",
    "    \"\"\"Compute average pairwise spatial similarity for a batch\"\"\"\n",
    "    B = latents_bchw.shape[0]\n",
    "    if B <= 1:\n",
    "        return 0.0\n",
    "    \n",
    "    # Compute spatial intensity (L2 norm across RGB)\n",
    "    spatial_intensity = torch.norm(latents_bchw, dim=1)  # [B, H, W]\n",
    "    spatial_flat = spatial_intensity.reshape(B, -1)  # [B, H*W]\n",
    "    spatial_norm = F.normalize(spatial_flat, dim=1)\n",
    "    \n",
    "    # Pairwise cosine similarity\n",
    "    similarity = torch.mm(spatial_norm, spatial_norm.t())\n",
    "    \n",
    "    # Mask diagonal and average\n",
    "    mask = torch.eye(B, device=latents_bchw.device, dtype=torch.bool)\n",
    "    similarity = similarity.masked_fill(mask, 0)\n",
    "    \n",
    "    return similarity.sum().item() / (B * (B - 1))\n",
    "\n",
    "# Compute diversity metric for each snapshot\n",
    "diversity_scores = []\n",
    "for snapshot in snapshots:\n",
    "    snapshot_tensor = torch.tensor(snapshot, dtype=torch.float32)\n",
    "    score = compute_pairwise_similarity(snapshot_tensor)\n",
    "    diversity_scores.append(score)\n",
    "\n",
    "# Plot diversity over time\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(snapshot_steps, diversity_scores, linewidth=2, marker='o', markersize=6)\n",
    "plt.axhline(y=0, color='green', linestyle='--', alpha=0.5, label='Perfect diversity')\n",
    "plt.xlabel('Step', fontsize=12)\n",
    "plt.ylabel('Average Pairwise Similarity', fontsize=12)\n",
    "plt.title('Spatial Diversity Metric (Lower = More Diverse)', fontsize=14)\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Initial similarity: {diversity_scores[0]:.4f}\")\n",
    "print(f\"Final similarity: {diversity_scores[-1]:.4f}\")\n",
    "print(f\"Change: {diversity_scores[-1] - diversity_scores[0]:.4f}\")\n",
    "print(f\"\\nLower values = more diverse spatial patterns\")\n",
    "print(f\"Negative values = patterns are pointing in opposite directions!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments to Try\n",
    "\n",
    "Go back to the \"Configure Loss Weights and Parameters\" cell and try:\n",
    "\n",
    "### 1. No Spatial Diversity (Baseline)\n",
    "```python\n",
    "weights = {\n",
    "    'magnitude': 5.0,\n",
    "    'coherence_infonce': 2.0,\n",
    "    'spatial_diversity': 0.0,  # DISABLED\n",
    "}\n",
    "```\n",
    "**Expected**: All latents will likely converge to similar patterns (same blob location)\n",
    "\n",
    "### 2. Strong Spatial Diversity\n",
    "```python\n",
    "weights = {\n",
    "    'magnitude': 5.0,\n",
    "    'coherence_infonce': 2.0,\n",
    "    'spatial_diversity': 5.0,  # VERY STRONG\n",
    "}\n",
    "spatial_diversity_temperature = 0.05  # Very aggressive\n",
    "```\n",
    "**Expected**: Very different spatial patterns (blobs in different locations/shapes)\n",
    "\n",
    "### 3. Only Spatial Diversity (No Coherence)\n",
    "```python\n",
    "weights = {\n",
    "    'magnitude': 5.0,\n",
    "    'coherence_infonce': 0.0,  # DISABLED\n",
    "    'spatial_diversity': 2.0,\n",
    "}\n",
    "```\n",
    "**Expected**: Diverse patterns but potentially noisy (no smoothness constraint)\n",
    "\n",
    "### 4. Vary Batch Size\n",
    "Try `batch_size = 2` vs `batch_size = 8` to see how many latents affect diversity pressure\n",
    "\n",
    "### 5. Vary Temperature\n",
    "Compare:\n",
    "- `spatial_diversity_temperature = 0.05` (very aggressive)\n",
    "- `spatial_diversity_temperature = 0.1` (aggressive)\n",
    "- `spatial_diversity_temperature = 0.5` (moderate)\n",
    "- `spatial_diversity_temperature = 1.0` (gentle)\n",
    "\n",
    "### 6. Adjust InfoNCE Radii\n",
    "**Tighter coherence** (smaller regions):\n",
    "```python\n",
    "infonce_positive_radius = 2.0\n",
    "infonce_negative_radius = 8.0\n",
    "```\n",
    "\n",
    "**Broader coherence** (larger regions):\n",
    "```python\n",
    "infonce_positive_radius = 5.0\n",
    "infonce_negative_radius = 15.0\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
