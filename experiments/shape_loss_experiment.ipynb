{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Shape Loss Experiment: Sculpting Objects from Noise\n\n[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/jtooates/blind_lm/blob/main/experiments/shape_loss_experiment.ipynb)\n\nThis notebook demonstrates how the object-forming losses can create shape-like patterns from pure Gaussian noise.\n\n**Key Idea**: We optimize pixel values directly (no neural network) using only loss functions as guidance.\n\n**What you'll see**: Random noise → distinct blob-like shapes with sharp boundaries"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Functions\n",
    "\n",
    "These are the same losses used in the single-channel training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_shape_losses(latent):\n",
    "    \"\"\"\n",
    "    Create losses that encourage shape-like structures.\n",
    "    \n",
    "    Args:\n",
    "        latent: [B, H, W] tensor to optimize\n",
    "    \n",
    "    Returns:\n",
    "        dict of loss components\n",
    "    \"\"\"\n",
    "    B, H, W = latent.shape\n",
    "    losses = {}\n",
    "    \n",
    "    # 1. Sparsity - most pixels should be background (near 0)\n",
    "    losses['sparsity'] = torch.mean(torch.abs(latent))\n",
    "    \n",
    "    # 2. Binary-ness - pixels should be either on or off\n",
    "    distance_from_binary = torch.min(\n",
    "        (latent - 1.0)**2,  # Distance from 1\n",
    "        (latent + 1.0)**2   # Distance from -1\n",
    "    )\n",
    "    losses['binary'] = torch.mean(distance_from_binary)\n",
    "    \n",
    "    # 3. Smoothness within objects (Total Variation)\n",
    "    dx = torch.abs(latent[:, 1:, :] - latent[:, :-1, :])\n",
    "    dy = torch.abs(latent[:, :, 1:] - latent[:, :, :-1])\n",
    "    losses['tv'] = torch.mean(dx) + torch.mean(dy)\n",
    "    \n",
    "    # 4. Object size - encourage ~20% of pixels to be bright\n",
    "    threshold = 0.5\n",
    "    binary_mask = (latent > threshold).float()\n",
    "    bright_ratio = torch.mean(binary_mask)\n",
    "    target_ratio = 0.2\n",
    "    losses['object_size'] = (bright_ratio - target_ratio)**2\n",
    "    \n",
    "    return losses\n",
    "\n",
    "\n",
    "def contrastive_shape_loss(latents):\n",
    "    \"\"\"\n",
    "    Contrastive loss: different latents should look different.\n",
    "    \"\"\"\n",
    "    B = latents.shape[0]\n",
    "    if B < 2:\n",
    "        return torch.tensor(0.0)\n",
    "    \n",
    "    # Flatten and normalize\n",
    "    flat = latents.reshape(B, -1)\n",
    "    flat_norm = F.normalize(flat, dim=1)\n",
    "    \n",
    "    # Compute similarity matrix\n",
    "    sim_matrix = torch.matmul(flat_norm, flat_norm.T)\n",
    "    \n",
    "    # Penalize similarity between different samples\n",
    "    mask = 1.0 - torch.eye(B).to(latents.device)\n",
    "    loss = torch.mean(torch.abs(sim_matrix) * mask)\n",
    "    \n",
    "    return loss\n",
    "\n",
    "print(\"✓ Loss functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Random Noise\n",
    "\n",
    "We start with Gaussian noise + a few random blob seeds to break symmetry:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_latents(batch_size=6, image_size=(32, 32), device='cpu'):\n",
    "    \"\"\"\n",
    "    Initialize latents with structured noise.\n",
    "    \"\"\"\n",
    "    H, W = image_size\n",
    "    latents = []\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        # Start with weak noise\n",
    "        noise = torch.randn(H, W) * 0.1\n",
    "        \n",
    "        # Add a few random blobs to break symmetry\n",
    "        for _ in range(2):\n",
    "            y = np.random.randint(5, H-5)\n",
    "            x = np.random.randint(5, W-5)\n",
    "            size = np.random.randint(3, 7)\n",
    "            \n",
    "            yy, xx = torch.meshgrid(\n",
    "                torch.arange(H) - y,\n",
    "                torch.arange(W) - x,\n",
    "                indexing='ij'\n",
    "            )\n",
    "            blob = torch.exp(-(yy**2 + xx**2) / (2 * size**2))\n",
    "            noise += blob * np.random.uniform(0.5, 1.5)\n",
    "        \n",
    "        latents.append(noise)\n",
    "    \n",
    "    latents = torch.stack(latents).to(device)\n",
    "    latents.requires_grad_(True)\n",
    "    \n",
    "    return latents\n",
    "\n",
    "# Initialize\n",
    "batch_size = 6\n",
    "latents = initialize_latents(batch_size=batch_size, device=device)\n",
    "\n",
    "# Visualize initial state\n",
    "fig, axes = plt.subplots(2, 3, figsize=(9, 6))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i in range(batch_size):\n",
    "    axes[i].imshow(latents[i].detach().cpu().numpy(), cmap='gray', vmin=-1.5, vmax=1.5)\n",
    "    axes[i].set_title(f'Initial Noise {i+1}')\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.suptitle('Initial Random Noise (with blob seeds)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"✓ Initialized {batch_size} latents of shape {latents.shape[1:]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Loss Weights\n",
    "\n",
    "**Try adjusting these!** Different weights create different types of patterns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss weights - EXPERIMENT WITH THESE!\n",
    "weights = {\n",
    "    'sparsity': 0.5,      # Higher = more black background\n",
    "    'binary': 0.3,        # Higher = sharper boundaries (less gray)\n",
    "    'tv': 0.1,            # Higher = smoother objects\n",
    "    'object_size': 1.0,   # Higher = enforces target size more strongly\n",
    "    'contrastive': 2.0    # Higher = more diverse patterns\n",
    "}\n",
    "\n",
    "# Optimization settings\n",
    "num_steps = 300\n",
    "learning_rate = 0.02\n",
    "\n",
    "print(\"Loss weights:\")\n",
    "for name, weight in weights.items():\n",
    "    print(f\"  {name:15s}: {weight:.2f}\")\n",
    "print(f\"\\nOptimization: {num_steps} steps @ lr={learning_rate}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Optimization\n",
    "\n",
    "Watch the noise transform into shapes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-initialize latents for fresh start\n",
    "latents = initialize_latents(batch_size=batch_size, device=device)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.Adam([latents], lr=learning_rate)\n",
    "\n",
    "# Track losses\n",
    "loss_history = []\n",
    "\n",
    "print(\"Starting optimization...\\n\")\n",
    "\n",
    "for step in range(num_steps):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Compute losses\n",
    "    shape_losses = create_shape_losses(latents)\n",
    "    contrast_loss = contrastive_shape_loss(latents)\n",
    "    \n",
    "    # Total weighted loss\n",
    "    total_loss = 0\n",
    "    for name, loss in shape_losses.items():\n",
    "        total_loss += loss * weights.get(name, 0.1)\n",
    "    total_loss += contrast_loss * weights.get('contrastive', 1.0)\n",
    "    \n",
    "    # Optimize\n",
    "    total_loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Clamp to valid range\n",
    "    with torch.no_grad():\n",
    "        latents.clamp_(-1.5, 1.5)\n",
    "    \n",
    "    loss_history.append(total_loss.item())\n",
    "    \n",
    "    # Print progress\n",
    "    if step % 50 == 0:\n",
    "        print(f\"Step {step:3d}/{num_steps}: Loss = {total_loss.item():.4f}\")\n",
    "        print(f\"  sparsity: {shape_losses['sparsity'].item():.4f}\")\n",
    "        print(f\"  binary: {shape_losses['binary'].item():.4f}\")\n",
    "        print(f\"  tv: {shape_losses['tv'].item():.4f}\")\n",
    "        print(f\"  object_size: {shape_losses['object_size'].item():.4f}\")\n",
    "        print(f\"  contrastive: {contrast_loss.item():.4f}\")\n",
    "        print()\n",
    "\n",
    "print(\"\\n✓ Optimization complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Results\n",
    "\n",
    "See the optimized shapes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, figsize=(12, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i in range(batch_size):\n",
    "    img = latents[i].detach().cpu().numpy()\n",
    "    axes[i].imshow(img, cmap='gray', vmin=-1.5, vmax=1.5)\n",
    "    axes[i].set_title(f'Optimized Shape {i+1}', fontsize=12)\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.suptitle('Gaussian Noise → Shapes (via losses only)', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Notice:\")\n",
    "print(\"  - Distinct blob-like shapes\")\n",
    "print(\"  - Sharp boundaries between black/white\")\n",
    "print(\"  - Sparse (mostly black background)\")\n",
    "print(\"  - Each shape is different (contrastive loss)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Loss Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(loss_history, linewidth=2)\n",
    "plt.xlabel('Optimization Step', fontsize=12)\n",
    "plt.ylabel('Total Loss', fontsize=12)\n",
    "plt.title('Loss During Optimization', fontsize=14)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Final loss: {loss_history[-1]:.4f}\")\n",
    "print(f\"Initial loss: {loss_history[0]:.4f}\")\n",
    "print(f\"Reduction: {(1 - loss_history[-1]/loss_history[0])*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment: Try Different Loss Weights\n",
    "\n",
    "Go back to the \"Configure Loss Weights\" cell and try:\n",
    "\n",
    "**More sparsity** (higher `sparsity` weight):\n",
    "- Creates smaller, sparser objects\n",
    "- More black background\n",
    "\n",
    "**More binary** (higher `binary` weight):\n",
    "- Sharper black/white contrast\n",
    "- Less gray values\n",
    "\n",
    "**More smoothness** (higher `tv` weight):\n",
    "- Smoother blob boundaries\n",
    "- Less texture within objects\n",
    "\n",
    "**Less contrastive** (lower `contrastive` weight):\n",
    "- Shapes may become more similar\n",
    "- Could collapse to identical patterns\n",
    "\n",
    "**More object_size** (higher `object_size` weight):\n",
    "- Enforces target size (20%) more strongly\n",
    "- More consistent object sizes across samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaway\n",
    "\n",
    "This experiment shows that **you don't need paired image-text data** to get image-like patterns.\n",
    "\n",
    "The right combination of losses can **sculpt structure out of noise** purely through optimization pressure.\n",
    "\n",
    "This is exactly what the text encoder learns to do:\n",
    "1. Map text → visual latent space\n",
    "2. Minimize these object-forming losses\n",
    "3. Naturally creates interpretable object-like patterns\n",
    "4. Different text → different shapes (via contrastive loss)\n",
    "5. Reconstruction loss ensures information is preserved"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}