{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Shape Loss Experiment: Sculpting Objects from Noise\n\n[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/jtooates/blind_lm/blob/main/experiments/shape_loss_experiment.ipynb)\n\nThis notebook demonstrates how the object-forming losses can create shape-like patterns from pure Gaussian noise.\n\n**Key Idea**: We optimize pixel values directly (no neural network) using only loss functions as guidance.\n\n**What you'll see**: Random noise → distinct blob-like shapes with sharp boundaries"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Functions\n",
    "\n",
    "These are the same losses used in the single-channel training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def create_shape_losses(latent):\n    \"\"\"\n    Create losses that encourage shape-like structures.\n    \n    Args:\n        latent: [B, H, W] tensor to optimize\n    \n    Returns:\n        dict of loss components\n    \"\"\"\n    B, H, W = latent.shape\n    losses = {}\n    \n    # 1. Sparsity - most pixels should be background (near 0)\n    losses['sparsity'] = torch.mean(torch.abs(latent))\n    \n    # 2. Binary-ness - pixels should be either on or off\n    distance_from_binary = torch.min(\n        (latent - 1.0)**2,  # Distance from 1\n        (latent + 1.0)**2   # Distance from -1\n    )\n    losses['binary'] = torch.mean(distance_from_binary)\n    \n    # 3. Smoothness within objects (Total Variation)\n    dx = torch.abs(latent[:, 1:, :] - latent[:, :-1, :])\n    dy = torch.abs(latent[:, :, 1:] - latent[:, :, :-1])\n    losses['tv'] = torch.mean(dx) + torch.mean(dy)\n    \n    # 4. Object size - encourage ~20% of pixels to be bright\n    threshold = 0.5\n    binary_mask = (latent > threshold).float()\n    bright_ratio = torch.mean(binary_mask)\n    target_ratio = 0.2\n    losses['object_size'] = (bright_ratio - target_ratio)**2\n    \n    # 5. Magnitude - prevent collapse to near-zero values\n    magnitude = torch.mean(torch.abs(latent))\n    min_magnitude = 0.3\n    losses['magnitude'] = torch.relu(min_magnitude - magnitude)\n    \n    return losses\n\n\ndef coherence_loss_autocorr(latent):\n    \"\"\"\n    Spatial Autocorrelation Loss (fully differentiable).\n    \n    Encourages nearby pixels to have similar values → coherent blobs.\n    High autocorrelation = coherent; low = scattered.\n    \n    Args:\n        latent: [B, H, W] tensor\n    \n    Returns:\n        loss value (we want to maximize autocorr, so return negative)\n    \"\"\"\n    # Compute correlation between adjacent pixels\n    dx = latent[:, 1:, :] * latent[:, :-1, :]  # Horizontal neighbors\n    dy = latent[:, :, 1:] * latent[:, :, :-1]  # Vertical neighbors\n    \n    autocorr = torch.mean(dx) + torch.mean(dy)\n    \n    # Maximize autocorrelation = minimize negative\n    return -autocorr\n\n\ndef coherence_loss_perimeter(latent, threshold=0.5, temperature=0.1):\n    \"\"\"\n    Perimeter-to-Area Loss (differentiable via soft thresholding).\n    \n    Minimizes edge length relative to area.\n    Scattered pixels: high perimeter/area → high loss\n    Compact blobs: low perimeter/area → low loss\n    \n    Args:\n        latent: [B, H, W] tensor\n        threshold: threshold for \"on\" pixels\n        temperature: softness of sigmoid (lower = sharper)\n    \n    Returns:\n        perimeter-to-area ratio\n    \"\"\"\n    # Soft thresholding (differentiable approximation)\n    binary_soft = torch.sigmoid((latent - threshold) / temperature)\n    \n    # Compute edges (boundaries)\n    dx = torch.abs(binary_soft[:, 1:, :] - binary_soft[:, :-1, :])\n    dy = torch.abs(binary_soft[:, :, 1:] - binary_soft[:, :, :-1])\n    \n    # Total edge length\n    edge_length = torch.sum(dx) + torch.sum(dy)\n    \n    # Total area (number of \"on\" pixels)\n    area = torch.sum(binary_soft) + 1e-6  # Avoid division by zero\n    \n    # Minimize ratio (compact shapes have low ratio)\n    return edge_length / area\n\n\ndef coherence_loss_morphological(latent):\n    \"\"\"\n    Morphological Smoothness Loss (fully differentiable).\n    \n    Applies max pooling to fill in gaps.\n    Scattered pixels differ a lot from smoothed version.\n    Coherent blobs differ little from smoothed version.\n    \n    Args:\n        latent: [B, H, W] tensor\n    \n    Returns:\n        MSE between original and morphologically smoothed\n    \"\"\"\n    # Add channel dimension for pooling\n    latent_4d = latent.unsqueeze(1)  # [B, 1, H, W]\n    \n    # Smooth via max pooling (fills in small gaps)\n    pooled = F.max_pool2d(latent_4d, kernel_size=3, stride=1, padding=1)\n    \n    # Inverse smoothing (min pooling via negation)\n    unpooled = -F.max_pool2d(-pooled, kernel_size=3, stride=1, padding=1)\n    \n    # Remove channel dimension\n    unpooled = unpooled.squeeze(1)\n    \n    # Scattered pixels differ; coherent blobs don't\n    return torch.mean((latent - unpooled) ** 2)\n\n\ndef contrastive_shape_loss(latents):\n    \"\"\"\n    Contrastive loss: different latents should look different.\n    \"\"\"\n    B = latents.shape[0]\n    if B < 2:\n        return torch.tensor(0.0)\n    \n    # Flatten and normalize\n    flat = latents.reshape(B, -1)\n    flat_norm = F.normalize(flat, dim=1)\n    \n    # Compute similarity matrix\n    sim_matrix = torch.matmul(flat_norm, flat_norm.T)\n    \n    # Penalize similarity between different samples\n    mask = 1.0 - torch.eye(B).to(latents.device)\n    loss = torch.mean(torch.abs(sim_matrix) * mask)\n    \n    return loss\n\nprint(\"✓ Loss functions defined\")\nprint(\"\\nAvailable coherence losses:\")\nprint(\"  1. autocorr      - Spatial autocorrelation (simplest)\")\nprint(\"  2. perimeter     - Perimeter-to-area ratio (most intuitive)\")\nprint(\"  3. morphological - Max pooling smoothness\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Random Noise\n",
    "\n",
    "We start with Gaussian noise + a few random blob seeds to break symmetry:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_latents(batch_size=6, image_size=(32, 32), device='cpu'):\n",
    "    \"\"\"\n",
    "    Initialize latents with structured noise.\n",
    "    \"\"\"\n",
    "    H, W = image_size\n",
    "    latents = []\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        # Start with weak noise\n",
    "        noise = torch.randn(H, W) * 0.1\n",
    "        \n",
    "        # Add a few random blobs to break symmetry\n",
    "        for _ in range(2):\n",
    "            y = np.random.randint(5, H-5)\n",
    "            x = np.random.randint(5, W-5)\n",
    "            size = np.random.randint(3, 7)\n",
    "            \n",
    "            yy, xx = torch.meshgrid(\n",
    "                torch.arange(H) - y,\n",
    "                torch.arange(W) - x,\n",
    "                indexing='ij'\n",
    "            )\n",
    "            blob = torch.exp(-(yy**2 + xx**2) / (2 * size**2))\n",
    "            noise += blob * np.random.uniform(0.5, 1.5)\n",
    "        \n",
    "        latents.append(noise)\n",
    "    \n",
    "    latents = torch.stack(latents).to(device)\n",
    "    latents.requires_grad_(True)\n",
    "    \n",
    "    return latents\n",
    "\n",
    "# Initialize\n",
    "batch_size = 6\n",
    "latents = initialize_latents(batch_size=batch_size, device=device)\n",
    "\n",
    "# Visualize initial state\n",
    "fig, axes = plt.subplots(2, 3, figsize=(9, 6))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i in range(batch_size):\n",
    "    axes[i].imshow(latents[i].detach().cpu().numpy(), cmap='gray', vmin=-1.5, vmax=1.5)\n",
    "    axes[i].set_title(f'Initial Noise {i+1}')\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.suptitle('Initial Random Noise (with blob seeds)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"✓ Initialized {batch_size} latents of shape {latents.shape[1:]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Loss Weights\n",
    "\n",
    "**Try adjusting these!** Different weights create different types of patterns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Loss weights - EXPERIMENT WITH THESE!\nweights = {\n    'sparsity': 0.1,       # Lower = allows brighter pixels (was 0.5)\n    'binary': 1.0,         # Higher = sharper boundaries (was 0.3)\n    'tv': 0.05,            # Lower = allows sharper edges (was 0.1)\n    'object_size': 2.0,    # Higher = enforces target size more (was 1.0)\n    'magnitude': 5.0,      # NEW - prevents collapse to zero\n    'contrastive': 2.0,    # Higher = more diverse patterns\n}\n\n# Choose coherence loss type (comment/uncomment to experiment)\ncoherence_type = 'autocorr'      # Options: 'autocorr', 'perimeter', 'morphological', None\ncoherence_weight = 2.0\n\n# Optimization settings\nnum_steps = 300\nlearning_rate = 0.02\n\nprint(\"Loss weights:\")\nfor name, weight in weights.items():\n    print(f\"  {name:15s}: {weight:.2f}\")\n\nif coherence_type:\n    print(f\"  {'coherence':15s}: {coherence_weight:.2f} (type: {coherence_type})\")\nelse:\n    print(f\"  {'coherence':15s}: disabled\")\n\nprint(f\"\\nOptimization: {num_steps} steps @ lr={learning_rate}\")\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"COHERENCE LOSS OPTIONS:\")\nprint(\"=\"*60)\nprint(\"'autocorr'       - Encourages nearby pixels to be similar\")\nprint(\"                   (simplest, fully differentiable)\")\nprint()\nprint(\"'perimeter'      - Minimizes edge length / area ratio\")\nprint(\"                   (most intuitive, uses soft thresholding)\")\nprint()\nprint(\"'morphological'  - Penalizes difference from max-pooled version\")\nprint(\"                   (medium complexity)\")\nprint()\nprint(\"None             - No coherence loss (may get scattered pixels)\")\nprint(\"=\"*60)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Optimization\n",
    "\n",
    "Watch the noise transform into shapes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Re-initialize latents for fresh start\nlatents = initialize_latents(batch_size=batch_size, device=device)\n\n# Optimizer\noptimizer = torch.optim.Adam([latents], lr=learning_rate)\n\n# Track losses\nloss_history = []\ncoherence_history = []\n\nprint(\"Starting optimization...\\n\")\n\nfor step in range(num_steps):\n    optimizer.zero_grad()\n    \n    # Compute shape losses\n    shape_losses = create_shape_losses(latents)\n    contrast_loss = contrastive_shape_loss(latents)\n    \n    # Compute coherence loss based on selected type\n    if coherence_type == 'autocorr':\n        coherence_loss = coherence_loss_autocorr(latents)\n    elif coherence_type == 'perimeter':\n        coherence_loss = coherence_loss_perimeter(latents)\n    elif coherence_type == 'morphological':\n        coherence_loss = coherence_loss_morphological(latents)\n    else:\n        coherence_loss = torch.tensor(0.0)\n    \n    # Total weighted loss\n    total_loss = 0\n    for name, loss in shape_losses.items():\n        total_loss += loss * weights.get(name, 0.1)\n    total_loss += contrast_loss * weights.get('contrastive', 1.0)\n    \n    if coherence_type:\n        total_loss += coherence_loss * coherence_weight\n    \n    # Optimize\n    total_loss.backward()\n    optimizer.step()\n    \n    # Clamp to valid range\n    with torch.no_grad():\n        latents.clamp_(-1.5, 1.5)\n    \n    loss_history.append(total_loss.item())\n    coherence_history.append(coherence_loss.item() if coherence_type else 0.0)\n    \n    # Print progress\n    if step % 50 == 0:\n        print(f\"Step {step:3d}/{num_steps}: Loss = {total_loss.item():.4f}\")\n        print(f\"  sparsity: {shape_losses['sparsity'].item():.4f}\")\n        print(f\"  binary: {shape_losses['binary'].item():.4f}\")\n        print(f\"  tv: {shape_losses['tv'].item():.4f}\")\n        print(f\"  object_size: {shape_losses['object_size'].item():.4f}\")\n        print(f\"  magnitude: {shape_losses['magnitude'].item():.4f}\")\n        print(f\"  contrastive: {contrast_loss.item():.4f}\")\n        if coherence_type:\n            print(f\"  coherence ({coherence_type}): {coherence_loss.item():.4f}\")\n        print()\n\nprint(\"\\n✓ Optimization complete!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Results\n",
    "\n",
    "See the optimized shapes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, figsize=(12, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i in range(batch_size):\n",
    "    img = latents[i].detach().cpu().numpy()\n",
    "    axes[i].imshow(img, cmap='gray', vmin=-1.5, vmax=1.5)\n",
    "    axes[i].set_title(f'Optimized Shape {i+1}', fontsize=12)\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.suptitle('Gaussian Noise → Shapes (via losses only)', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Notice:\")\n",
    "print(\"  - Distinct blob-like shapes\")\n",
    "print(\"  - Sharp boundaries between black/white\")\n",
    "print(\"  - Sparse (mostly black background)\")\n",
    "print(\"  - Each shape is different (contrastive loss)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Loss Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(loss_history, linewidth=2)\n",
    "plt.xlabel('Optimization Step', fontsize=12)\n",
    "plt.ylabel('Total Loss', fontsize=12)\n",
    "plt.title('Loss During Optimization', fontsize=14)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Final loss: {loss_history[-1]:.4f}\")\n",
    "print(f\"Initial loss: {loss_history[0]:.4f}\")\n",
    "print(f\"Reduction: {(1 - loss_history[-1]/loss_history[0])*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Experiment: Try Different Coherence Losses\n\nGo back to the \"Configure Loss Weights\" cell and try different `coherence_type` values:\n\n### Coherence Loss Comparison\n\n**`coherence_type = 'autocorr'`** (Spatial Autocorrelation):\n- Encourages nearby pixels to have similar values\n- Creates smooth, connected blobs\n- Fully differentiable, no hyperparameters\n- **Recommended starting point**\n\n**`coherence_type = 'perimeter'`** (Perimeter-to-Area Ratio):\n- Minimizes edge length relative to area (like surface tension)\n- Creates compact, circular blobs\n- Most geometrically intuitive\n- Uses soft thresholding with `temperature` parameter\n\n**`coherence_type = 'morphological'`** (Max Pooling Smoothness):\n- Penalizes pixels that disappear after smoothing\n- Creates robust blobs that survive pooling\n- Medium complexity\n\n**`coherence_type = None`** (No coherence):\n- May result in scattered pixels instead of blobs\n- Useful for comparison to see coherence effect\n\n### Other Loss Weight Experiments\n\n**More magnitude** (higher `magnitude` weight):\n- Prevents collapse to near-zero values\n- Forces stronger signals\n\n**More binary** (higher `binary` weight):\n- Sharper black/white contrast\n- Less gray values\n\n**More coherence** (higher `coherence_weight`):\n- Larger, more connected blobs\n- Fewer scattered pixels\n\n**Less sparsity** (lower `sparsity` weight):\n- Allows more pixels to be active\n- Larger or more numerous objects"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaway\n",
    "\n",
    "This experiment shows that **you don't need paired image-text data** to get image-like patterns.\n",
    "\n",
    "The right combination of losses can **sculpt structure out of noise** purely through optimization pressure.\n",
    "\n",
    "This is exactly what the text encoder learns to do:\n",
    "1. Map text → visual latent space\n",
    "2. Minimize these object-forming losses\n",
    "3. Naturally creates interpretable object-like patterns\n",
    "4. Different text → different shapes (via contrastive loss)\n",
    "5. Reconstruction loss ensures information is preserved"
   ]
  },
  {
   "cell_type": "code",
   "source": "# Compare all coherence loss types\nprint(\"Comparing coherence losses: None vs autocorr vs perimeter vs morphological\\n\")\n\ncoherence_types = [None, 'autocorr', 'perimeter', 'morphological']\nresults = {}\n\n# Use same initial noise for fair comparison\ntorch.manual_seed(42)\nnp.random.seed(42)\ninitial_latents = initialize_latents(batch_size=4, device=device)\n\nfor coh_type in coherence_types:\n    print(f\"Training with coherence_type = {coh_type}...\")\n    \n    # Copy initial latents\n    latents = initial_latents.clone().detach()\n    latents.requires_grad_(True)\n    \n    optimizer = torch.optim.Adam([latents], lr=0.02)\n    \n    for step in range(200):  # Shorter for comparison\n        optimizer.zero_grad()\n        \n        shape_losses = create_shape_losses(latents)\n        contrast_loss = contrastive_shape_loss(latents)\n        \n        # Compute coherence loss\n        if coh_type == 'autocorr':\n            coh_loss = coherence_loss_autocorr(latents)\n        elif coh_type == 'perimeter':\n            coh_loss = coherence_loss_perimeter(latents)\n        elif coh_type == 'morphological':\n            coh_loss = coherence_loss_morphological(latents)\n        else:\n            coh_loss = torch.tensor(0.0)\n        \n        # Total loss\n        total_loss = (\n            0.1 * shape_losses['sparsity'] +\n            1.0 * shape_losses['binary'] +\n            0.05 * shape_losses['tv'] +\n            2.0 * shape_losses['object_size'] +\n            5.0 * shape_losses['magnitude'] +\n            2.0 * contrast_loss\n        )\n        \n        if coh_type:\n            total_loss += 2.0 * coh_loss\n        \n        total_loss.backward()\n        optimizer.step()\n        \n        with torch.no_grad():\n            latents.clamp_(-1.5, 1.5)\n    \n    results[coh_type if coh_type else 'none'] = latents.detach().cpu()\n    print(f\"  ✓ Complete\\n\")\n\n# Visualize comparison\nfig, axes = plt.subplots(4, 4, figsize=(12, 12))\n\nfor row, coh_type in enumerate(['none', 'autocorr', 'perimeter', 'morphological']):\n    for col in range(4):\n        img = results[coh_type][col].numpy()\n        axes[row, col].imshow(img, cmap='gray', vmin=-1.5, vmax=1.5)\n        \n        if col == 0:\n            axes[row, col].set_ylabel(f\"{coh_type}\", fontsize=12, fontweight='bold')\n        \n        axes[row, col].axis('off')\n\nplt.suptitle('Coherence Loss Comparison\\n(each row uses different coherence loss)', \n             fontsize=14, fontweight='bold')\nplt.tight_layout()\nplt.show()\n\nprint(\"\\nNotice how coherence losses create more connected blobs:\")\nprint(\"  - 'none': May have scattered pixels\")\nprint(\"  - 'autocorr': Smooth, connected blobs\")\nprint(\"  - 'perimeter': Compact, circular blobs\")\nprint(\"  - 'morphological': Robust blobs that survive pooling\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Advanced: Compare All Coherence Losses Side-by-Side\n\nRun this cell to see how different coherence losses affect the results:",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}