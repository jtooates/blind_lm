{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Latent Evolution: Watch a Shape Form\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/jtooates/blind_lm/blob/main/experiments/single_latent_evolution.ipynb)\n",
    "\n",
    "This notebook lets you watch a **single latent image** evolve step-by-step under different loss functions.\n",
    "\n",
    "**Purpose**: Understand how each loss affects the visual appearance during optimization.\n",
    "\n",
    "**Workflow**:\n",
    "1. Configure loss weights\n",
    "2. Start with random noise\n",
    "3. Watch it transform into a shape frame-by-frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_losses(latent):\n",
    "    \"\"\"\n",
    "    Compute all loss components for a single latent [H, W].\n",
    "    Returns dict of individual losses.\n",
    "    \"\"\"\n",
    "    # Add batch dimension for compatibility\n",
    "    latent_batch = latent.unsqueeze(0)  # [1, H, W]\n",
    "    losses = {}\n",
    "    \n",
    "    # 1. Sparsity: encourages most pixels → 0 (background)\n",
    "    losses['sparsity'] = torch.mean(torch.abs(latent))\n",
    "    \n",
    "    # 2. Binary: pushes pixels toward -1 or +1 (sharp black/white)\n",
    "    distance_from_binary = torch.min(\n",
    "        (latent - 1.0)**2,\n",
    "        (latent + 1.0)**2\n",
    "    )\n",
    "    losses['binary'] = torch.mean(distance_from_binary)\n",
    "    \n",
    "    # 3. Total Variation: smoothness within regions (penalizes edges)\n",
    "    dx = torch.abs(latent[1:, :] - latent[:-1, :])\n",
    "    dy = torch.abs(latent[:, 1:] - latent[:, :-1])\n",
    "    losses['tv'] = torch.mean(dx) + torch.mean(dy)\n",
    "    \n",
    "    # 4. Object Size: enforces target ratio of bright pixels\n",
    "    threshold = 0.5\n",
    "    binary_mask = (latent > threshold).float()\n",
    "    bright_ratio = torch.mean(binary_mask)\n",
    "    target_ratio = 0.25\n",
    "    losses['object_size'] = (bright_ratio - target_ratio)**2\n",
    "    \n",
    "    # 5. Magnitude: prevents collapse to near-zero values\n",
    "    magnitude = torch.mean(torch.abs(latent))\n",
    "    min_magnitude = 0.3\n",
    "    losses['magnitude'] = torch.relu(min_magnitude - magnitude)\n",
    "    \n",
    "    # 6. Autocorrelation: encourages spatially connected blobs\n",
    "    dx_corr = latent[1:, :] * latent[:-1, :]\n",
    "    dy_corr = latent[:, 1:] * latent[:, :-1]\n",
    "    autocorr = torch.mean(dx_corr) + torch.mean(dy_corr)\n",
    "    losses['coherence_autocorr'] = -autocorr  # Negative because we want high autocorr\n",
    "    \n",
    "    # 7. Perimeter-to-Area: compact blobs vs scattered pixels\n",
    "    temperature = 0.1\n",
    "    binary_soft = torch.sigmoid((latent - threshold) / temperature)\n",
    "    dx_edge = torch.abs(binary_soft[1:, :] - binary_soft[:-1, :])\n",
    "    dy_edge = torch.abs(binary_soft[:, 1:] - binary_soft[:, :-1])\n",
    "    edge_length = torch.sum(dx_edge) + torch.sum(dy_edge)\n",
    "    area = torch.sum(binary_soft) + 1e-6\n",
    "    losses['coherence_perimeter'] = edge_length / area\n",
    "    \n",
    "    # 8. Morphological: penalizes scattered pixels\n",
    "    latent_4d = latent_batch.unsqueeze(1)  # [1, 1, H, W]\n",
    "    pooled = F.max_pool2d(latent_4d, kernel_size=3, stride=1, padding=1)\n",
    "    unpooled = -F.max_pool2d(-pooled, kernel_size=3, stride=1, padding=1)\n",
    "    unpooled = unpooled.squeeze()\n",
    "    losses['coherence_morphological'] = torch.mean((latent - unpooled) ** 2)\n",
    "    \n",
    "    return losses\n",
    "\n",
    "print(\"✓ Loss functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configure Loss Weights\n",
    "\n",
    "**Adjust these to control what the image looks like!**\n",
    "\n",
    "Set any weight to `0` to disable that loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# LOSS WEIGHTS - EXPERIMENT WITH THESE!\n",
    "# ============================================================================\n",
    "\n",
    "weights = {\n",
    "    # Sparsity: encourages most pixels → 0 (background)\n",
    "    # Higher = more black background, fewer active pixels\n",
    "    'sparsity': 0.1,\n",
    "    \n",
    "    # Binary: pushes pixels toward -1 or +1 (sharp black/white)\n",
    "    # Higher = sharper boundaries, less gray\n",
    "    'binary': 1.0,\n",
    "    \n",
    "    # Total Variation: smoothness within regions (penalizes edges)\n",
    "    # Higher = smoother blobs, fewer sharp edges\n",
    "    'tv': 0.05,\n",
    "    \n",
    "    # Object Size: enforces target ratio of bright pixels (~25%)\n",
    "    # Higher = stronger enforcement of target coverage\n",
    "    'object_size': 2.0,\n",
    "    \n",
    "    # Magnitude: prevents collapse to near-zero values\n",
    "    # Higher = forces stronger signals\n",
    "    'magnitude': 5.0,\n",
    "    \n",
    "    # Coherence (choose ONE or mix):\n",
    "    'coherence_autocorr': 2.0,        # Spatial autocorrelation (recommended)\n",
    "    'coherence_perimeter': 0.0,       # Perimeter-to-area ratio\n",
    "    'coherence_morphological': 0.0,   # Morphological smoothness\n",
    "}\n",
    "\n",
    "# ============================================================================\n",
    "# OPTIMIZATION SETTINGS\n",
    "# ============================================================================\n",
    "\n",
    "num_steps = 500              # Total optimization steps\n",
    "snapshot_interval = 25       # Save visualization every N steps\n",
    "learning_rate = 0.02         # Adam learning rate\n",
    "image_size = 32              # Latent is 32x32\n",
    "random_seed = 42             # For reproducibility (None = random)\n",
    "\n",
    "# ============================================================================\n",
    "\n",
    "print(\"Configuration:\")\n",
    "print(f\"  Total steps: {num_steps}\")\n",
    "print(f\"  Snapshots every {snapshot_interval} steps\")\n",
    "print(f\"  Expected snapshots: {num_steps // snapshot_interval + 1}\")\n",
    "print(f\"  Learning rate: {learning_rate}\")\n",
    "print(f\"\\nActive losses:\")\n",
    "for name, weight in weights.items():\n",
    "    if weight > 0:\n",
    "        print(f\"  {name:25s}: {weight:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initialize Single Latent\n",
    "\n",
    "Start with Gaussian noise + a blob seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed if specified\n",
    "if random_seed is not None:\n",
    "    torch.manual_seed(random_seed)\n",
    "    np.random.seed(random_seed)\n",
    "\n",
    "# Initialize single latent [H, W]\n",
    "latent = torch.randn(image_size, image_size) * 0.1\n",
    "\n",
    "# Add a random blob to break symmetry\n",
    "for _ in range(2):\n",
    "    y = np.random.randint(5, image_size - 5)\n",
    "    x = np.random.randint(5, image_size - 5)\n",
    "    size = np.random.randint(3, 7)\n",
    "    \n",
    "    yy, xx = torch.meshgrid(\n",
    "        torch.arange(image_size) - y,\n",
    "        torch.arange(image_size) - x,\n",
    "        indexing='ij'\n",
    "    )\n",
    "    blob = torch.exp(-(yy**2 + xx**2) / (2 * size**2))\n",
    "    latent += blob * np.random.uniform(0.5, 1.5)\n",
    "\n",
    "latent = latent.to(device)\n",
    "latent.requires_grad_(True)\n",
    "\n",
    "# Visualize initial state\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.imshow(latent.detach().cpu().numpy(), cmap='gray', vmin=-1.5, vmax=1.5)\n",
    "plt.title('Initial Latent (Step 0)', fontsize=14, fontweight='bold')\n",
    "plt.colorbar(label='Pixel Value')\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"✓ Initialized latent: {latent.shape}\")\n",
    "print(f\"  Min value: {latent.min().item():.3f}\")\n",
    "print(f\"  Max value: {latent.max().item():.3f}\")\n",
    "print(f\"  Mean value: {latent.mean().item():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run Optimization with Snapshots\n",
    "\n",
    "Watch the latent evolve step by step!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset latent (re-run cell above if you want new random init)\n",
    "optimizer = torch.optim.Adam([latent], lr=learning_rate)\n",
    "\n",
    "# Storage for snapshots\n",
    "snapshots = []\n",
    "snapshot_steps = []\n",
    "loss_history = []\n",
    "\n",
    "# Save initial state\n",
    "snapshots.append(latent.detach().cpu().numpy().copy())\n",
    "snapshot_steps.append(0)\n",
    "\n",
    "print(\"Starting optimization...\\n\")\n",
    "\n",
    "for step in range(num_steps):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Compute all losses\n",
    "    losses = compute_losses(latent)\n",
    "    \n",
    "    # Build weighted total loss\n",
    "    total_loss = sum(losses[name] * weights[name] for name in losses if name in weights)\n",
    "    \n",
    "    # Optimize\n",
    "    total_loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Clamp to valid range\n",
    "    with torch.no_grad():\n",
    "        latent.clamp_(-1.5, 1.5)\n",
    "    \n",
    "    loss_history.append(total_loss.item())\n",
    "    \n",
    "    # Save snapshot\n",
    "    if (step + 1) % snapshot_interval == 0:\n",
    "        snapshots.append(latent.detach().cpu().numpy().copy())\n",
    "        snapshot_steps.append(step + 1)\n",
    "        print(f\"Step {step + 1:3d}/{num_steps}: Loss = {total_loss.item():.4f}\")\n",
    "\n",
    "# Save final state if not already saved\n",
    "if num_steps % snapshot_interval != 0:\n",
    "    snapshots.append(latent.detach().cpu().numpy().copy())\n",
    "    snapshot_steps.append(num_steps)\n",
    "\n",
    "print(f\"\\n✓ Optimization complete!\")\n",
    "print(f\"  Captured {len(snapshots)} snapshots\")\n",
    "print(f\"  Final loss: {loss_history[-1]:.4f}\")\n",
    "print(f\"  Initial loss: {loss_history[0]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualize Evolution\n",
    "\n",
    "See all snapshots in a grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate grid size\n",
    "num_snapshots = len(snapshots)\n",
    "cols = min(5, num_snapshots)\n",
    "rows = (num_snapshots + cols - 1) // cols\n",
    "\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(cols * 3, rows * 3))\n",
    "if rows == 1:\n",
    "    axes = axes.reshape(1, -1)\n",
    "if cols == 1:\n",
    "    axes = axes.reshape(-1, 1)\n",
    "\n",
    "for idx, (snapshot, step) in enumerate(zip(snapshots, snapshot_steps)):\n",
    "    row = idx // cols\n",
    "    col = idx % cols\n",
    "    \n",
    "    ax = axes[row, col]\n",
    "    ax.imshow(snapshot, cmap='gray', vmin=-1.5, vmax=1.5)\n",
    "    ax.set_title(f'Step {step}', fontsize=10)\n",
    "    ax.axis('off')\n",
    "\n",
    "# Hide unused subplots\n",
    "for idx in range(num_snapshots, rows * cols):\n",
    "    row = idx // cols\n",
    "    col = idx % cols\n",
    "    axes[row, col].axis('off')\n",
    "\n",
    "plt.suptitle('Latent Evolution Over Time', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nEvolution summary:\")\n",
    "print(f\"  Initial → Final: {snapshot_steps[0]} → {snapshot_steps[-1]} steps\")\n",
    "print(f\"  You can see the transformation from random noise to structured shape!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Plot Loss Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(loss_history, linewidth=2)\n",
    "\n",
    "# Mark snapshot points\n",
    "for step in snapshot_steps[1:]:  # Skip initial\n",
    "    if step < len(loss_history):\n",
    "        plt.axvline(x=step, color='red', alpha=0.3, linestyle='--', linewidth=1)\n",
    "\n",
    "plt.xlabel('Optimization Step', fontsize=12)\n",
    "plt.ylabel('Total Loss', fontsize=12)\n",
    "plt.title('Loss During Optimization (red lines = snapshots)', fontsize=14)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Loss reduction: {(loss_history[0] - loss_history[-1]) / abs(loss_history[0]) * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Side-by-Side Comparison\n",
    "\n",
    "See initial vs final clearly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "# Initial\n",
    "axes[0].imshow(snapshots[0], cmap='gray', vmin=-1.5, vmax=1.5)\n",
    "axes[0].set_title(f'Initial (Step {snapshot_steps[0]})', fontsize=14, fontweight='bold')\n",
    "axes[0].axis('off')\n",
    "\n",
    "# Final\n",
    "axes[1].imshow(snapshots[-1], cmap='gray', vmin=-1.5, vmax=1.5)\n",
    "axes[1].set_title(f'Final (Step {snapshot_steps[-1]})', fontsize=14, fontweight='bold')\n",
    "axes[1].axis('off')\n",
    "\n",
    "plt.suptitle('Transformation: Noise → Shape', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print statistics\n",
    "print(\"Initial latent:\")\n",
    "print(f\"  Min: {snapshots[0].min():.3f}\")\n",
    "print(f\"  Max: {snapshots[0].max():.3f}\")\n",
    "print(f\"  Mean: {snapshots[0].mean():.3f}\")\n",
    "print(f\"  Std: {snapshots[0].std():.3f}\")\n",
    "\n",
    "print(\"\\nFinal latent:\")\n",
    "print(f\"  Min: {snapshots[-1].min():.3f}\")\n",
    "print(f\"  Max: {snapshots[-1].max():.3f}\")\n",
    "print(f\"  Mean: {snapshots[-1].mean():.3f}\")\n",
    "print(f\"  Std: {snapshots[-1].std():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Analyze Individual Loss Components\n",
    "\n",
    "See how each loss evolves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recompute losses at each snapshot\n",
    "loss_components_history = {name: [] for name in weights.keys()}\n",
    "\n",
    "for snapshot in snapshots:\n",
    "    snapshot_tensor = torch.tensor(snapshot, dtype=torch.float32)\n",
    "    losses = compute_losses(snapshot_tensor)\n",
    "    for name in weights.keys():\n",
    "        loss_components_history[name].append(losses[name].item())\n",
    "\n",
    "# Plot active losses\n",
    "active_losses = {name: values for name, values in loss_components_history.items() \n",
    "                if weights[name] > 0}\n",
    "\n",
    "if active_losses:\n",
    "    fig, axes = plt.subplots(len(active_losses), 1, figsize=(10, 3 * len(active_losses)))\n",
    "    if len(active_losses) == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for ax, (name, values) in zip(axes, active_losses.items()):\n",
    "        ax.plot(snapshot_steps, values, linewidth=2, marker='o')\n",
    "        ax.set_xlabel('Step', fontsize=10)\n",
    "        ax.set_ylabel('Loss Value', fontsize=10)\n",
    "        ax.set_title(f'{name} (weight={weights[name]:.2f})', fontsize=12, fontweight='bold')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No active losses to plot (all weights are 0)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments to Try\n",
    "\n",
    "Go back to the \"Configure Loss Weights\" cell and try:\n",
    "\n",
    "### 1. Pure Coherence (No Other Losses)\n",
    "```python\n",
    "weights = {\n",
    "    'sparsity': 0.0,\n",
    "    'binary': 0.0,\n",
    "    'tv': 0.0,\n",
    "    'object_size': 0.0,\n",
    "    'magnitude': 0.0,\n",
    "    'coherence_autocorr': 2.0,\n",
    "}\n",
    "```\n",
    "**Expected**: Smooth blobs, but may drift toward all positive or all negative\n",
    "\n",
    "### 2. Coherence + Magnitude (Prevent Collapse)\n",
    "```python\n",
    "weights = {\n",
    "    'magnitude': 5.0,\n",
    "    'coherence_autocorr': 2.0,\n",
    "}\n",
    "```\n",
    "**Expected**: Blobs with guaranteed signal strength\n",
    "\n",
    "### 3. Full Stack (Recommended)\n",
    "```python\n",
    "weights = {\n",
    "    'sparsity': 0.1,\n",
    "    'binary': 1.0,\n",
    "    'tv': 0.05,\n",
    "    'object_size': 2.0,\n",
    "    'magnitude': 5.0,\n",
    "    'coherence_autocorr': 2.0,\n",
    "}\n",
    "```\n",
    "**Expected**: Clean, compact blobs on sparse background\n",
    "\n",
    "### 4. Compare Coherence Types\n",
    "Try each coherence loss individually to see the difference:\n",
    "- `coherence_autocorr`: Smooth, connected\n",
    "- `coherence_perimeter`: Compact, circular\n",
    "- `coherence_morphological`: Robust to smoothing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
