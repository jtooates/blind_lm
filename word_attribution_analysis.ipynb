{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Word Attribution Analysis\n\n[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/jtooates/blind_lm/blob/main/word_attribution_analysis.ipynb)\n\nThis notebook analyzes which parts of the RGB latent are responsible for generating each word.\n\n**Method**: Gradient-based attribution - compute ∂(logit)/∂(latent) to see which pixels influence each word's prediction."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 1. Environment Setup"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Check GPU availability\nimport torch\nprint(\"=\"*70)\nprint(\"GPU Check\")\nprint(\"=\"*70)\nprint(f\"GPU Available: {torch.cuda.is_available()}\")\nif torch.cuda.is_available():\n    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n    print(f\"CUDA Version: {torch.version.cuda}\")\nelse:\n    print(\"⚠️  Note: No GPU found. Running on CPU (slower but will work).\")\nprint(\"=\"*70)"
  },
  {
   "cell_type": "code",
   "source": "# Install dependencies\nprint(\"Installing dependencies...\")\n!pip install -q transformers torch matplotlib numpy\n\n# Suppress tokenizer warning\nimport os\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n\nprint(\"✓ Dependencies installed\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Clone repository (for Colab)\nif IN_COLAB:\n    import os\n    repo_dir = 'blind_lm'\n    repo_url = 'https://github.com/jtooates/blind_lm.git'\n    \n    if os.path.exists(repo_dir):\n        print(\"Repository already exists. Pulling latest changes...\")\n        %cd blind_lm\n        !git pull origin main\n        print(\"✓ Repository updated\")\n    else:\n        print(\"Cloning repository...\")\n        !git clone {repo_url}\n        %cd blind_lm\n        print(\"✓ Repository cloned\")\nelse:\n    print(\"✓ Skipping clone (running locally)\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Mount Google Drive (for Colab)\ntry:\n    from google.colab import drive\n    drive.mount('/content/drive')\n    IN_COLAB = True\n    print(\"✓ Google Drive mounted\")\n    print(\"✓ Checkpoints location: /content/drive/MyDrive/blind_lm_outputs/\")\nexcept:\n    IN_COLAB = False\n    print(\"✓ Running locally\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "## 2. Load Model",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom pathlib import Path\nimport json\nimport sys\nimport os\n\n# Add phase1 to path (handle both Colab and local)\nif IN_COLAB:\n    # In Colab, we're already in /content/blind_lm after cloning\n    sys.path.insert(0, '/content/blind_lm/phase1')\n    os.chdir('/content/blind_lm')  # Ensure we're in repo root\nelse:\n    # Local: assume we're running from repo root\n    sys.path.insert(0, 'phase1')\n\nfrom model import create_model\nfrom decoder_nonar import create_decoder\nfrom transformers import AutoTokenizer\n\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nprint(f\"Using device: {device}\")\n\n# Determine checkpoint location based on environment\nif IN_COLAB:\n    checkpoint_dir = Path('/content/drive/MyDrive/blind_lm_outputs/phase1_rgb_infonce')\nelse:\n    checkpoint_dir = Path('outputs/phase1_rgb_infonce')\n\ncheckpoint_path = checkpoint_dir / 'checkpoint_latest.pt'\nconfig_path = checkpoint_dir / 'config.json'\n\n# Check if files exist\nif not checkpoint_path.exists():\n    print(f\"❌ Checkpoint not found at {checkpoint_path}\")\n    print(\"\\nPlease ensure you have a trained model.\")\n    if IN_COLAB:\n        print(\"Expected location: /content/drive/MyDrive/blind_lm_outputs/phase1_rgb_infonce/\")\n        print(\"You can train a model using phase1_colab_training.ipynb\")\n    else:\n        print(\"Expected location: outputs/phase1_rgb_infonce/\")\n    raise FileNotFoundError(f\"Checkpoint not found: {checkpoint_path}\")\n\nif not config_path.exists():\n    print(f\"❌ Config not found at {config_path}\")\n    raise FileNotFoundError(f\"Config not found: {config_path}\")\n\nprint(f\"✓ Found checkpoint: {checkpoint_path}\")\nprint(f\"✓ Found config: {config_path}\")\n\n# Load config\nwith open(config_path) as f:\n    config = json.load(f)\n\nprint(f\"\\nModel configuration:\")\nprint(f\"  Channels: {config['model']['num_channels']} (RGB)\")\nprint(f\"  Grid size: {config['model']['grid_size']}x{config['model']['grid_size']}\")\nprint(f\"  Hidden size: {config['model']['hidden_size']}\")\n\n# Create models\nencoder = create_model(config['model']).to(device)\ndecoder = create_decoder(config['decoder']).to(device)\n\n# Load checkpoint\ncheckpoint = torch.load(checkpoint_path, map_location=device)\nencoder.load_state_dict(checkpoint['encoder_state_dict'])\ndecoder.load_state_dict(checkpoint['decoder_state_dict'])\nencoder.eval()\ndecoder.eval()\n\nprint(f\"\\n✓ Loaded checkpoint from step {checkpoint['step']}\")\n\n# Create tokenizer\ntokenizer = AutoTokenizer.from_pretrained('gpt2')\ntokenizer.pad_token = tokenizer.eos_token\n\nprint(\"✓ Models loaded and ready!\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "## 3. Attribution Functions",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "## 4. Interactive Analysis\n\nEnter a sentence to analyze which parts of the latent are responsible for each word."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attribution Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "## 5. Analysis Tips\n\n**What to look for:**\n\n1. **Color words** (red, blue, yellow): Do they activate specific colored regions?\n2. **Spatial words** (under, right, left): Do they activate specific spatial patterns?\n3. **Object words** (cube, block, box): Do they have consistent activation patterns?\n4. **Function words** (the, is): Typically should have low/diffuse activation\n\n**Heatmap interpretation:**\n- **Bright (yellow/white)**: High importance - this pixel strongly influenced the word\n- **Dark (red/black)**: Low importance - this pixel didn't affect the word much\n\n**Questions to explore:**\n- Do different occurrences of \"the\" activate different regions?\n- Do color words consistently activate the same colored blobs?\n- Do spatial relations show positional patterns in the latent?"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 6. Try More Sentences\n\nRun the cell below multiple times with different sentences to explore patterns."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt for sentence\n",
    "sentence = input(\"Enter a sentence to analyze: \")\n",
    "\n",
    "if not sentence.strip():\n",
    "    sentence = \"the red cube is under the yellow block\"  # Default example\n",
    "    print(f\"Using default: {sentence}\")\n",
    "\n",
    "# Generate visualization\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "fig, tokens, heatmaps = visualize_word_attributions(encoder, decoder, tokenizer, sentence, device)\n",
    "print(\"=\"*70)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis Tips\n",
    "\n",
    "**What to look for:**\n",
    "\n",
    "1. **Color words** (red, blue, yellow): Do they activate specific colored regions?\n",
    "2. **Spatial words** (under, right, left): Do they activate specific spatial patterns?\n",
    "3. **Object words** (cube, block, box): Do they have consistent activation patterns?\n",
    "4. **Function words** (the, is): Typically should have low/diffuse activation\n",
    "\n",
    "**Heatmap interpretation:**\n",
    "- **Bright (yellow/white)**: High importance - this pixel strongly influenced the word\n",
    "- **Dark (red/black)**: Low importance - this pixel didn't affect the word much\n",
    "\n",
    "**Questions to explore:**\n",
    "- Do different occurrences of \"the\" activate different regions?\n",
    "- Do color words consistently activate the same colored blobs?\n",
    "- Do spatial relations show positional patterns in the latent?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try More Sentences\n",
    "\n",
    "Run the cell below multiple times with different sentences to explore patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example sentences to try:\n",
    "examples = [\n",
    "    \"the red cube is under the yellow block\",\n",
    "    \"the blue box is right of the green sphere\",\n",
    "    \"the yellow block is on the red cube\",\n",
    "    \"the green cube is left of the blue box\",\n",
    "]\n",
    "\n",
    "print(\"Example sentences you can try:\")\n",
    "for i, ex in enumerate(examples, 1):\n",
    "    print(f\"{i}. {ex}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "sentence = input(\"Enter a sentence (or leave blank for random example): \")\n",
    "\n",
    "if not sentence.strip():\n",
    "    import random\n",
    "    sentence = random.choice(examples)\n",
    "    print(f\"Using random example: {sentence}\")\n",
    "\n",
    "fig, tokens, heatmaps = visualize_word_attributions(encoder, decoder, tokenizer, sentence, device)\n",
    "print(\"=\"*70)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}